{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cosine_sim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\John Kim\\Desktop\\git projects\\kdrama-data\\recommender\\test.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 111>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/John%20Kim/Desktop/git%20projects/kdrama-data/recommender/test.ipynb#ch0000000?line=100'>101</a>\u001b[0m     \u001b[39mprint\u001b[39m(title_list)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/John%20Kim/Desktop/git%20projects/kdrama-data/recommender/test.ipynb#ch0000000?line=102'>103</a>\u001b[0m \u001b[39m# kw_vector = vectorize_kdrama('keywords')\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/John%20Kim/Desktop/git%20projects/kdrama-data/recommender/test.ipynb#ch0000000?line=103'>104</a>\u001b[0m \u001b[39m# kw_sim = find_similarity(kw_vector)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/John%20Kim/Desktop/git%20projects/kdrama-data/recommender/test.ipynb#ch0000000?line=104'>105</a>\u001b[0m \u001b[39m# g_vector = vectorize_kdrama('genres')\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/John%20Kim/Desktop/git%20projects/kdrama-data/recommender/test.ipynb#ch0000000?line=107'>108</a>\u001b[0m \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/John%20Kim/Desktop/git%20projects/kdrama-data/recommender/test.ipynb#ch0000000?line=108'>109</a>\u001b[0m \u001b[39m# get_rec(1, g_sim, df)\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/John%20Kim/Desktop/git%20projects/kdrama-data/recommender/test.ipynb#ch0000000?line=110'>111</a>\u001b[0m sim_data \u001b[39m=\u001b[39m create_similarity_data(\u001b[39m\"\u001b[39;49m\u001b[39mHospital Playlist\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\John Kim\\Desktop\\git projects\\kdrama-data\\recommender\\test.ipynb Cell 1'\u001b[0m in \u001b[0;36mcreate_similarity_data\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/John%20Kim/Desktop/git%20projects/kdrama-data/recommender/test.ipynb#ch0000000?line=74'>75</a>\u001b[0m label_weights \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/John%20Kim/Desktop/git%20projects/kdrama-data/recommender/test.ipynb#ch0000000?line=75'>76</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mkeywords\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m0.4\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/John%20Kim/Desktop/git%20projects/kdrama-data/recommender/test.ipynb#ch0000000?line=76'>77</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mgenres\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m0.3\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/John%20Kim/Desktop/git%20projects/kdrama-data/recommender/test.ipynb#ch0000000?line=79'>80</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mscreenwriter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m0.05\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/John%20Kim/Desktop/git%20projects/kdrama-data/recommender/test.ipynb#ch0000000?line=80'>81</a>\u001b[0m }\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/John%20Kim/Desktop/git%20projects/kdrama-data/recommender/test.ipynb#ch0000000?line=82'>83</a>\u001b[0m target_index \u001b[39m=\u001b[39m search_kdrama(name, indices)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/John%20Kim/Desktop/git%20projects/kdrama-data/recommender/test.ipynb#ch0000000?line=83'>84</a>\u001b[0m top_ten \u001b[39m=\u001b[39m get_recommended_kdramas(target_index, cosine_sim, df)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/John%20Kim/Desktop/git%20projects/kdrama-data/recommender/test.ipynb#ch0000000?line=85'>86</a>\u001b[0m \u001b[39mfor\u001b[39;00m kdrama \u001b[39min\u001b[39;00m top_ten:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/John%20Kim/Desktop/git%20projects/kdrama-data/recommender/test.ipynb#ch0000000?line=86'>87</a>\u001b[0m     \u001b[39m# adds this title to dictionary\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/John%20Kim/Desktop/git%20projects/kdrama-data/recommender/test.ipynb#ch0000000?line=87'>88</a>\u001b[0m     similarity_data[\u001b[39m\"\u001b[39m\u001b[39mtitles\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(kdrama)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cosine_sim' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer # vectorizes the data\n",
    "from sklearn.metrics.pairwise import cosine_similarity # finds similarity between vectors\n",
    "\n",
    "import pandas as pd # dataframe library\n",
    "\n",
    "filename = r\"C:\\Users\\John Kim\\Desktop\\kdrama_data.csv\"\n",
    "\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "df = df[['title', 'description', 'keywords', 'genres', 'actors', 'director', 'screenwriter']]\n",
    "\n",
    "def fill_na():\n",
    "    df.replace(\"N/A\", \"\")\n",
    "    for label in df.columns:\n",
    "        df[label] = df[label].fillna('') # fills N/A values with \"\"\n",
    "\n",
    "fill_na()\n",
    "\n",
    "def og_cos_sim():\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = tfidf.fit_transform(df['keywords'] + \" \" + df['genres']\n",
    "    + \" \" + df['actors'] + \" \" + df['director'] + \" \" + df['screenwriter'])\n",
    "    return cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "indices = pd.Series(df.index, index=df['title'])\n",
    "indices = indices[~indices.index.duplicated(keep='last')]\n",
    "\n",
    "def search_kdrama(kdrama_name, kdrama_indices):\n",
    "    return kdrama_indices[kdrama_indices.index.str.contains(kdrama_name, regex=False, na=False)][0] # returns top value\n",
    "\n",
    "def get_recommended_kdramas(target_kdrama_index, kdrama_similarities, kdramas_df):\n",
    "    similarity_scores = pd.DataFrame(kdrama_similarities[target_kdrama_index], columns=[\"score\"])\n",
    "    kdrama_indices = similarity_scores.sort_values(\"score\", ascending=False)[1:11].index\n",
    "    return kdramas_df['title'].iloc[kdrama_indices].values\n",
    "\n",
    "def get_rec(target_kdrama_index, kdrama_similarities, kdramas_df):\n",
    "    similarity_scores = kdrama_similarities[target_kdrama_index]\n",
    "    # kdrama_indices = similarity_scores.sort_values(\"score\", ascending=False)[0:11].index\n",
    "    # return similarity_scores\n",
    "    return similarity_scores[search_kdrama(\"Hospital Playlist 2\", indices)]\n",
    "    return pd.concat([kdramas_df['title'].iloc[kdrama_indices], similarity_scores.iloc[kdrama_indices]], axis = 1)\n",
    "\n",
    "\n",
    "def get_score(og_name, rec_name, indices, sim):\n",
    "    rec_index = search_kdrama(rec_name, indices)\n",
    "    scores = sim[search_kdrama(og_name, indices)]\n",
    "    return scores[rec_index]\n",
    "\n",
    "def vectorize_kdrama(col_name):\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    return tfidf.fit_transform(df[col_name])\n",
    "\n",
    "def find_similarity(matrix):\n",
    "    return cosine_similarity(matrix, matrix)\n",
    "\n",
    "top_ten = get_recommended_kdramas(1, og_cos_sim(), df)\n",
    "# get list of top 10 similar kdrama\n",
    "# for each kdrama, calculate its similarity on keywords, genres, actors, director, and screenwriter\n",
    "    # find this kdrama's similarity based on its name (find id through it)\n",
    "\n",
    "# keywords \n",
    "\n",
    "labels_used = [\"keywords\", \"genres\", \"actors\", \"director\", \"screenwriter\"]\n",
    "\n",
    "def create_similarity_data(name):\n",
    "    similarity_data = {\n",
    "        \"titles\": [],\n",
    "        \"keywords\": [],\n",
    "        \"genres\": [],\n",
    "        \"actors\": [],\n",
    "        \"director\": [],\n",
    "        \"screenwriter\": [],\n",
    "    }\n",
    "\n",
    "    label_weights = {\n",
    "        \"keywords\": 0.4,\n",
    "        \"genres\": 0.3,\n",
    "        \"actors\": 0.2,\n",
    "        \"director\": 0.05,\n",
    "        \"screenwriter\": 0.05,\n",
    "    }\n",
    "\n",
    "    target_index = search_kdrama(name, indices)\n",
    "    top_ten = get_recommended_kdramas(target_index, cosine_sim, df)\n",
    "\n",
    "    for kdrama in top_ten:\n",
    "        # adds this title to dictionary\n",
    "        similarity_data[\"titles\"].append(kdrama)\n",
    "        for label in labels_used:\n",
    "            vec = vectorize_kdrama(label)\n",
    "            sim = find_similarity(vec)\n",
    "            label_score = get_score(name, kdrama, indices, sim) * label_weights[label]\n",
    "            # print(label_score)\n",
    "            similarity_data[label].append(label_score)\n",
    "    \n",
    "    return similarity_data\n",
    "\n",
    "def get_titles():\n",
    "    np_titles = df['title'].to_numpy()\n",
    "    title_list = np_titles.tolist()\n",
    "    print(title_list)\n",
    "\n",
    "# kw_vector = vectorize_kdrama('keywords')\n",
    "# kw_sim = find_similarity(kw_vector)\n",
    "# g_vector = vectorize_kdrama('genres')\n",
    "# g_sim = find_similarity(g_vector)\n",
    "\n",
    "\n",
    "# get_rec(1, g_sim, df)\n",
    "\n",
    "sim_data = create_similarity_data(\"Hospital Playlist\")\n",
    "\n",
    "# sim[0]\n",
    "# cosine_sim[0]\n",
    "# df.head()\n",
    "# 3032 length\n",
    "# print(indices)\n",
    "# search_kdrama(\"Move\", indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'og_cos_sim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\John Kim\\Desktop\\git projects\\kdrama-data\\recommender\\test.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/John%20Kim/Desktop/git%20projects/kdrama-data/recommender/test.ipynb#ch0000016?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(og_cos_sim())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'og_cos_sim' is not defined"
     ]
    }
   ],
   "source": [
    "print(og_cos_sim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>keywords</th>\n",
       "      <th>genres</th>\n",
       "      <th>actors</th>\n",
       "      <th>director</th>\n",
       "      <th>screenwriter</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hospital Playlist 2</td>\n",
       "      <td>0.178722</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.778722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Soulmate</td>\n",
       "      <td>0.227953</td>\n",
       "      <td>0.103355</td>\n",
       "      <td>0.024170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006814</td>\n",
       "      <td>0.362293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Be Melodramatic</td>\n",
       "      <td>0.197267</td>\n",
       "      <td>0.107724</td>\n",
       "      <td>0.048888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eulachacha Waikiki 2</td>\n",
       "      <td>0.181517</td>\n",
       "      <td>0.123625</td>\n",
       "      <td>0.040540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lovestruck in the City</td>\n",
       "      <td>0.150603</td>\n",
       "      <td>0.108463</td>\n",
       "      <td>0.038474</td>\n",
       "      <td>0.018764</td>\n",
       "      <td>0.021127</td>\n",
       "      <td>0.337429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A-Teen</td>\n",
       "      <td>0.185335</td>\n",
       "      <td>0.104484</td>\n",
       "      <td>0.043625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Anniversary Anyway</td>\n",
       "      <td>0.179174</td>\n",
       "      <td>0.116939</td>\n",
       "      <td>0.034479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.330592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Love Playlist: Season 2</td>\n",
       "      <td>0.148973</td>\n",
       "      <td>0.108463</td>\n",
       "      <td>0.053791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011548</td>\n",
       "      <td>0.322775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Love Playlist: Season 4</td>\n",
       "      <td>0.211414</td>\n",
       "      <td>0.016369</td>\n",
       "      <td>0.039643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007324</td>\n",
       "      <td>0.274750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Love (ft. Marriage and Divorce)</td>\n",
       "      <td>0.115447</td>\n",
       "      <td>0.115988</td>\n",
       "      <td>0.042493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.273929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            titles  keywords    genres    actors  director  \\\n",
       "0              Hospital Playlist 2  0.178722  0.300000  0.200000  0.050000   \n",
       "6                         Soulmate  0.227953  0.103355  0.024170  0.000000   \n",
       "1                  Be Melodramatic  0.197267  0.107724  0.048888  0.000000   \n",
       "3             Eulachacha Waikiki 2  0.181517  0.123625  0.040540  0.000000   \n",
       "8           Lovestruck in the City  0.150603  0.108463  0.038474  0.018764   \n",
       "2                           A-Teen  0.185335  0.104484  0.043625  0.000000   \n",
       "7               Anniversary Anyway  0.179174  0.116939  0.034479  0.000000   \n",
       "5          Love Playlist: Season 2  0.148973  0.108463  0.053791  0.000000   \n",
       "4          Love Playlist: Season 4  0.211414  0.016369  0.039643  0.000000   \n",
       "9  Love (ft. Marriage and Divorce)  0.115447  0.115988  0.042493  0.000000   \n",
       "\n",
       "   screenwriter     score  \n",
       "0      0.050000  0.778722  \n",
       "6      0.006814  0.362293  \n",
       "1      0.000000  0.353878  \n",
       "3      0.000000  0.345682  \n",
       "8      0.021127  0.337429  \n",
       "2      0.000000  0.333444  \n",
       "7      0.000000  0.330592  \n",
       "5      0.011548  0.322775  \n",
       "4      0.007324  0.274750  \n",
       "9      0.000000  0.273929  "
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame(sim_data)\n",
    "new_df['score'] = new_df.sum(axis=1, numeric_only=True)\n",
    "new_df = new_df.sort_values(\"score\", ascending=False)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       19  1930s  1950s  1960s  1970s  1980s  1990s  2000s  2ne1  abandoned  \\\n",
      "0     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   0.0        0.0   \n",
      "1     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   0.0        0.0   \n",
      "2     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   0.0        0.0   \n",
      "3     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   0.0        0.0   \n",
      "4     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   0.0        0.0   \n",
      "...   ...    ...    ...    ...    ...    ...    ...    ...   ...        ...   \n",
      "3027  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   0.0        0.0   \n",
      "3028  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   0.0        0.0   \n",
      "3029  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   0.0        0.0   \n",
      "3030  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   0.0        0.0   \n",
      "3031  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   0.0        0.0   \n",
      "\n",
      "      ...  yura   ze  zeze   zn  zombie  zombies  zone   zu  zuho  zuny  \n",
      "0     ...   0.0  0.0   0.0  0.0     0.0      0.0   0.0  0.0   0.0   0.0  \n",
      "1     ...   0.0  0.0   0.0  0.0     0.0      0.0   0.0  0.0   0.0   0.0  \n",
      "2     ...   0.0  0.0   0.0  0.0     0.0      0.0   0.0  0.0   0.0   0.0  \n",
      "3     ...   0.0  0.0   0.0  0.0     0.0      0.0   0.0  0.0   0.0   0.0  \n",
      "4     ...   0.0  0.0   0.0  0.0     0.0      0.0   0.0  0.0   0.0   0.0  \n",
      "...   ...   ...  ...   ...  ...     ...      ...   ...  ...   ...   ...  \n",
      "3027  ...   0.0  0.0   0.0  0.0     0.0      0.0   0.0  0.0   0.0   0.0  \n",
      "3028  ...   0.0  0.0   0.0  0.0     0.0      0.0   0.0  0.0   0.0   0.0  \n",
      "3029  ...   0.0  0.0   0.0  0.0     0.0      0.0   0.0  0.0   0.0   0.0  \n",
      "3030  ...   0.0  0.0   0.0  0.0     0.0      0.0   0.0  0.0   0.0   0.0  \n",
      "3031  ...   0.0  0.0   0.0  0.0     0.0      0.0   0.0  0.0   0.0   0.0  \n",
      "\n",
      "[3032 rows x 2364 columns]\n"
     ]
    }
   ],
   "source": [
    "def get_recommended_kdramas(target_kdrama_index, kdrama_similarities, kdramas_df):\n",
    "    similarity_scores = pd.DataFrame(kdrama_similarities[target_kdrama_index], columns=[\"score\"])\n",
    "    kdrama_indices = similarity_scores.sort_values(\"score\", ascending=False)[1:11].index\n",
    "    return pd.concat([kdramas_df['title'].iloc[kdrama_indices], similarity_scores.iloc[kdrama_indices]], axis = 1)\n",
    "\n",
    "\n",
    "print(pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "df['Synopsis'] = df['Synopsis'].fillna('') # null synposis = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1853)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix = tfidf.fit_transform(df['Synopsis'])\n",
    "tfidf_matrix.shape # (100, 1853) means 100 movies, 1853 unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.00672245, 0.01857485, 0.        , 0.04389825,\n",
       "       0.04899857, 0.        , 0.0051677 , 0.00652825, 0.        ,\n",
       "       0.02324584, 0.        , 0.00660733, 0.02052612, 0.        ,\n",
       "       0.        , 0.00637876, 0.00541432, 0.01489357, 0.02412528,\n",
       "       0.02917888, 0.        , 0.        , 0.01836815, 0.01931049,\n",
       "       0.        , 0.        , 0.00936167, 0.02332473, 0.01842789,\n",
       "       0.        , 0.        , 0.        , 0.01726747, 0.01194718,\n",
       "       0.01797403, 0.02007764, 0.00642033, 0.01068586, 0.        ,\n",
       "       0.0235464 , 0.05099411, 0.        , 0.00723527, 0.        ,\n",
       "       0.03692231, 0.18003975, 0.01240955, 0.02886854, 0.0282077 ,\n",
       "       0.01657028, 0.08602724, 0.        , 0.        , 0.        ,\n",
       "       0.01538312, 0.        , 0.        , 0.01919222, 0.01252548,\n",
       "       0.        , 0.01655885, 0.01152103, 0.        , 0.        ,\n",
       "       0.03381299, 0.01628826, 0.00475315, 0.0258285 , 0.        ,\n",
       "       0.02381831, 0.        , 0.        , 0.01617681, 0.        ,\n",
       "       0.00992964, 0.01963289, 0.00823228, 0.04639724, 0.        ,\n",
       "       0.        , 0.01401301, 0.17409186, 0.        , 0.03659297,\n",
       "       0.02111975, 0.02797476, 0.01297098, 0.        , 0.02551302,\n",
       "       0.01541465, 0.01078482, 0.        , 0.03849792, 0.0359151 ,\n",
       "       0.        , 0.        , 0.00865184, 0.05731921, 0.        ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix) # calculates similarity between each drama (?)\n",
    "cosine_sim[0][1] # compares similarity between number 1 movie with number 2 movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Move to Heaven            0\n",
       "Hospital Playlist         1\n",
       "Flower of Evil            2\n",
       "Hospital Playlist 2       3\n",
       "My Mister                 4\n",
       "                       ... \n",
       "Never Give Up          3027\n",
       "Doctor Lawyer          3028\n",
       "My Rocket Ship         3029\n",
       "Gold Mask              3030\n",
       "Master's Delicacies    3031\n",
       "Length: 3032, dtype: int64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = pd.Series(df.index, index=df['title'])\n",
    "indices = indices[~indices.index.duplicated(keep='last')]\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_kdrama_index = indices['Move to Heaven'] # lets us get its indices\n",
    "target_kdrama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.043898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.008652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.057319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       score\n",
       "0   1.000000\n",
       "1   0.006722\n",
       "2   0.018575\n",
       "3   0.000000\n",
       "4   0.043898\n",
       "..       ...\n",
       "95  0.000000\n",
       "96  0.000000\n",
       "97  0.008652\n",
       "98  0.057319\n",
       "99  0.000000\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_scores = pd.DataFrame(cosine_sim[target_kdrama_index], columns = [\"score\"])\n",
    "similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    Move to Heaven\n",
       "46                          Misaeng\n",
       "82                          Save Me\n",
       "51                 The Fiery Priest\n",
       "98    Because This Is My First Life\n",
       "41          While You Were Sleeping\n",
       "5                   Prison Playbook\n",
       "78                       Squid Game\n",
       "4                         My Mister\n",
       "93                  Beautiful World\n",
       "45        Arthdal Chronicles Part 2\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kdrama_indices = similarity_scores.sort_values(\"score\", ascending=False)[0:11].index\n",
    "df['Name'].iloc[kdrama_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Move to Heaven                 0\n",
       "It's Okay to Not Be Okay       9\n",
       "Hometown Cha-Cha-Cha          28\n",
       "Hot Stove League              59\n",
       "Ghost Doctor                  67\n",
       "                            ... \n",
       "Inspector Park Moon Soo     2849\n",
       "Into The Storm              2905\n",
       "Stormy Season               2952\n",
       "Welcome to Wedding Hell     3024\n",
       "Doctor Lawyer               3028\n",
       "Length: 173, dtype: int64"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search_kdrama(kdrama_name, kdrama_indices):\n",
    "    return kdrama_indices[kdrama_indices.index.str.contains(kdrama_name, na=False)]\n",
    "\n",
    "search_kdrama('to', indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1                   Hospital Playlist\n",
       "3                 Hospital Playlist 2\n",
       "43                     Dr. Romantic 2\n",
       "10                             Signal\n",
       "66                 Children of Nobody\n",
       "26    Weightlifting Fairy Kim Bok Joo\n",
       "96                        Doctor John\n",
       "6                          Reply 1988\n",
       "53             Descendants of the Sun\n",
       "18                             Healer\n",
       "42                    Dear My Friends\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_recommended_kdramas(target_kdrama_index, kdrama_similarities, kdramas_df):\n",
    "    similarity_scores = pd.DataFrame(kdrama_similarities[target_kdrama_index], columns=[\"score\"])\n",
    "    kdrama_indices = similarity_scores.sort_values(\"score\", ascending=False)[0:11].index\n",
    "    return kdramas_df['Name'].iloc[kdrama_indices]\n",
    "\n",
    "get_recommended_kdramas(1, cosine_sim, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Move to Heaven</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2578</th>\n",
       "      <td>Rickety Rackety Family</td>\n",
       "      <td>0.448618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>Love is All Around</td>\n",
       "      <td>0.439893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765</th>\n",
       "      <td>August Bride</td>\n",
       "      <td>0.422961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>Air City</td>\n",
       "      <td>0.422093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957</th>\n",
       "      <td>Dinosaur Teacher</td>\n",
       "      <td>0.420758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>Hong Gil Dong</td>\n",
       "      <td>0.409530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>Romance</td>\n",
       "      <td>0.406494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>Aster</td>\n",
       "      <td>0.406494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2315</th>\n",
       "      <td>I Love You, Don't Cry</td>\n",
       "      <td>0.405790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>I'm Sorry, I Love You</td>\n",
       "      <td>0.401231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title     score\n",
       "0             Move to Heaven  1.000000\n",
       "2578  Rickety Rackety Family  0.448618\n",
       "1920      Love is All Around  0.439893\n",
       "2765            August Bride  0.422961\n",
       "1232                Air City  0.422093\n",
       "2957       Dinosaur Teacher   0.420758\n",
       "2210           Hong Gil Dong  0.409530\n",
       "2946                 Romance  0.406494\n",
       "2727                   Aster  0.406494\n",
       "2315   I Love You, Don't Cry  0.405790\n",
       "390    I'm Sorry, I Love You  0.401231"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer # vectorizes the data\n",
    "from sklearn.metrics.pairwise import cosine_similarity # finds similarity between vectors\n",
    "\n",
    "import pandas as pd # dataframe library\n",
    "\n",
    "filename = r\"C:\\Users\\John Kim\\Desktop\\kdrama_data.csv\"\n",
    "\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "df = df[['title', 'description', 'keywords', 'genres', 'actors', 'director', 'screenwriter']]\n",
    "\n",
    "def fill_na():\n",
    "    df.replace(\"N/A\", \"\")\n",
    "    for label in df.columns:\n",
    "        df[label] = df[label].fillna('') # fills N/A values with \"\"\n",
    "\n",
    "fill_na()\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vector = vectorizer.fit_transform(df['keywords'] + \" \" + df['genres']\n",
    " + \" \" + df['actors'] + \" \" + df['director'] + \" \" + df['screenwriter'])\n",
    "\n",
    "cs = cosine_similarity(vector, vector)\n",
    "\n",
    "indices = pd.Series(df.index, index=df['title'])\n",
    "indices = indices[~indices.index.duplicated(keep='last')]\n",
    "\n",
    "def search_kdrama(kdrama_name, kdrama_indices):\n",
    "    return kdrama_indices[kdrama_indices.index.str.contains(kdrama_name, regex=False, na=False)]\n",
    "\n",
    "def get_recommended_kdramas(target_kdrama_index, kdrama_similarities, kdramas_df):\n",
    "    similarity_scores = pd.DataFrame(kdrama_similarities[target_kdrama_index], columns=[\"score\"])\n",
    "    kdrama_indices = similarity_scores.sort_values(\"score\", ascending=False)[0:11].index\n",
    "    return pd.concat([kdramas_df['title'].iloc[kdrama_indices], similarity_scores.iloc[kdrama_indices]], axis = 1)\n",
    "\n",
    "get_recommended_kdramas(0, cs, df)\n",
    "# search_kdrama(\"(ft. Marriage and Divorce)\", indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   titles  keywords    genres    actors  director  \\\n",
      "5           3 Leaf Clover  0.097333  0.259808  0.065134  0.000000   \n",
      "6               Navillera  0.078259  0.259808  0.060302  0.000000   \n",
      "2                   Uncle  0.080100  0.173205  0.095743  0.000000   \n",
      "8  The Light in Your Eyes  0.075431  0.173205  0.070353  0.016667   \n",
      "1  Rickety Rackety Family  0.000000  0.200000  0.120605  0.000000   \n",
      "0             Good Doctor  0.093068  0.173205  0.032824  0.011785   \n",
      "4      Panda and Hedgehog  0.069369  0.154919  0.070353  0.000000   \n",
      "7                Air City  0.000000  0.000000  0.111658  0.000000   \n",
      "3             Pluto Squad  0.000000  0.000000  0.065134  0.000000   \n",
      "\n",
      "   screenwriter     score  \n",
      "5      0.000000  0.422274  \n",
      "6      0.000000  0.398368  \n",
      "2      0.016667  0.365715  \n",
      "8      0.000000  0.335656  \n",
      "1      0.000000  0.320605  \n",
      "0      0.000000  0.310883  \n",
      "4      0.000000  0.294641  \n",
      "7      0.007001  0.118660  \n",
      "3      0.000000  0.065134  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # dataframe library\n",
    "from sklearn.feature_extraction.text import CountVectorizer # vectorizes the data\n",
    "from sklearn.metrics.pairwise import cosine_similarity  # finds similarity between vectors\n",
    "\n",
    "# filename = \"csv\\shows.csv\"\n",
    "filename = r\"C:\\Users\\John Kim\\Desktop\\kdrama_data.csv\"\n",
    "\n",
    "label_weights = {\n",
    "        \"keywords\": 0.4,\n",
    "        \"genres\": 0.3,\n",
    "        \"actors\": 0.2,\n",
    "        \"director\": 0.05,\n",
    "        \"screenwriter\": 0.05,\n",
    "    }\n",
    "\n",
    "df = pd.read_csv(filename)\n",
    "df = df[['title', 'description', 'keywords', 'genres', 'actors', 'director', 'screenwriter']]\n",
    "\n",
    "def fill_na():\n",
    "    \"\"\"replaces na values with an empty string\"\"\"\n",
    "    df.replace(\"N/A\", \"\")\n",
    "    for label in df.columns:\n",
    "        df[label] = df[label].fillna('') # fills N/A values with \"\"\n",
    "\n",
    "fill_na()\n",
    "def get_indices():\n",
    "    indices = pd.Series(df.index, index=df['title'])\n",
    "    return indices[~indices.index.duplicated(keep='last')]\n",
    "\n",
    "def og_cos_sim():\n",
    "    \"\"\"the similarity scores used to get the initial top x kdramas\"\"\"\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = tfidf.fit_transform(df['keywords'] + \" \" + df['genres']\n",
    "    + \" \" + df['actors'] + \" \" + df['director'] + \" \" + df['screenwriter'])\n",
    "    return cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "def search_kdrama(kdrama_name, kdrama_indices):\n",
    "    \"\"\"searches for kdrama with matching name and returns top result\"\"\"\n",
    "    return kdrama_indices[kdrama_indices.index.str.contains(kdrama_name, regex=False, na=False)][0] \n",
    "\n",
    "def get_recommended_kdramas(target_kdrama_index, kdrama_similarities, kdramas_df, rec_num):\n",
    "    \"\"\"returns the top (rec_num) recommended kdramas based on keywords, genres, actors, director, director\n",
    "    and screenwriter (we recalculate their similarity score by using our own 'weights' :omg:)\"\"\"\n",
    "    if rec_num <= 1:\n",
    "        # return no kdramas\n",
    "        return False\n",
    "\n",
    "    # should set a max on how many recommended kdrama you can get (maybe like 25 or 50?)\n",
    "    similarity_scores = pd.DataFrame(kdrama_similarities[target_kdrama_index], columns=[\"score\"])\n",
    "    kdrama_indices = similarity_scores.sort_values(\"score\", ascending=False)[1:rec_num].index # gets top 10 (we can change this)\n",
    "    return kdramas_df['title'].iloc[kdrama_indices].values # converts to array\n",
    "\n",
    "def get_score(og_name, rec_name, indices, sim):\n",
    "    \"\"\"gets the similarity score of a kdrama based on ONE aspect (e.g. only keywords)\"\"\"\n",
    "    rec_index = search_kdrama(rec_name, indices)\n",
    "    scores = sim[search_kdrama(og_name, indices)]\n",
    "    return scores[rec_index]\n",
    "\n",
    "def vectorize_kdrama(col_name):\n",
    "    \"\"\"vectorizes the kdrama based on ONE aspect (e.g. only keywords)\"\"\"\n",
    "    cv = CountVectorizer(stop_words='english')\n",
    "    return cv.fit_transform(df[col_name])\n",
    "\n",
    "def find_similarity(matrix):\n",
    "    \"\"\"finds the similarity between this matrix's kdrama and everything else\"\"\"\n",
    "    return cosine_similarity(matrix, matrix)\n",
    "\n",
    "def create_similarity_data(name):\n",
    "    \"\"\"creates a dictionary of arrays with the top 10 similar kdramas\"\"\"\n",
    "    similarity_data = {\n",
    "        \"titles\": [],\n",
    "        \"keywords\": [],\n",
    "        \"genres\": [],\n",
    "        \"actors\": [],\n",
    "        \"director\": [],\n",
    "        \"screenwriter\": [],\n",
    "    }\n",
    "\n",
    "    target_index = search_kdrama(name, get_indices())\n",
    "    top_ten = get_recommended_kdramas(target_index, og_cos_sim(), df, 10)\n",
    "\n",
    "    for kdrama in top_ten:\n",
    "        # adds this title to dictionary\n",
    "        similarity_data[\"titles\"].append(kdrama)\n",
    "        for label in label_weights.keys():\n",
    "            vec = vectorize_kdrama(label)\n",
    "            sim = find_similarity(vec)\n",
    "            label_score = get_score(name, kdrama, get_indices(), sim) * label_weights[label]\n",
    "            # print(label_score)\n",
    "            similarity_data[label].append(label_score)\n",
    "    \n",
    "    return similarity_data\n",
    "\n",
    "def get_top_rec_kdrama(name):\n",
    "    \"\"\"reorders the top recommended kdramas and converts to a dataframe\"\"\"\n",
    "    data = create_similarity_data(name)\n",
    "    new_df = pd.DataFrame(data)\n",
    "    new_df['score'] = new_df.sum(axis=1, numeric_only=True)\n",
    "    new_df = new_df.sort_values(\"score\", ascending=False)\n",
    "    print(new_df)\n",
    "\n",
    "get_top_rec_kdrama(\"Move to Heaven\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   titles  keywords    genres    actors  director  \\\n",
      "5           3 Leaf Clover  0.065633  0.286191  0.021389  0.000000   \n",
      "6               Navillera  0.042971  0.234580  0.061668  0.000000   \n",
      "0             Good Doctor  0.121485  0.145018  0.034254  0.006304   \n",
      "1  Rickety Rackety Family  0.000000  0.173329  0.100621  0.000000   \n",
      "8  The Light in Your Eyes  0.046327  0.177272  0.040299  0.009205   \n",
      "2                   Uncle  0.073009  0.111234  0.047082  0.000000   \n",
      "4      Panda and Hedgehog  0.050807  0.121811  0.054045  0.000000   \n",
      "3             Pluto Squad  0.000000  0.000000  0.087092  0.000000   \n",
      "7                Air City  0.000000  0.000000  0.078783  0.000000   \n",
      "\n",
      "   screenwriter     score  \n",
      "5      0.000000  0.373213  \n",
      "6      0.000000  0.339219  \n",
      "0      0.000000  0.307061  \n",
      "1      0.000000  0.273950  \n",
      "8      0.000000  0.273102  \n",
      "2      0.012221  0.243545  \n",
      "4      0.000000  0.226663  \n",
      "3      0.000000  0.087092  \n",
      "7      0.006611  0.085394  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # dataframe library\n",
    "from sklearn.feature_extraction.text import \\\n",
    "    TfidfVectorizer  # vectorizes the data\n",
    "from sklearn.metrics.pairwise import \\\n",
    "    cosine_similarity  # finds similarity between vectors\n",
    "\n",
    "# filename = \"csv\\shows.csv\"\n",
    "filename = r\"C:\\Users\\John Kim\\Desktop\\kdrama_data.csv\"\n",
    "\n",
    "label_weights = {\n",
    "        \"keywords\": 0.4,\n",
    "        \"genres\": 0.3,\n",
    "        \"actors\": 0.2,\n",
    "        \"director\": 0.05,\n",
    "        \"screenwriter\": 0.05,\n",
    "    }\n",
    "\n",
    "df = pd.read_csv(filename)\n",
    "df = df[['title', 'description', 'keywords', 'genres', 'actors', 'director', 'screenwriter']]\n",
    "\n",
    "def fill_na():\n",
    "    \"\"\"replaces na values with an empty string\"\"\"\n",
    "    df.replace(\"N/A\", \"\")\n",
    "    for label in df.columns:\n",
    "        df[label] = df[label].fillna('') # fills N/A values with \"\"\n",
    "\n",
    "def get_indices():\n",
    "    indices = pd.Series(df.index, index=df['title'])\n",
    "    return indices[~indices.index.duplicated(keep='last')]\n",
    "\n",
    "def og_cos_sim():\n",
    "    \"\"\"the similarity scores used to get the initial top x kdramas\"\"\"\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = tfidf.fit_transform(df['keywords'] + \" \" + df['genres']\n",
    "    + \" \" + df['actors'] + \" \" + df['director'] + \" \" + df['screenwriter'])\n",
    "    return cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "def search_kdrama(kdrama_name, kdrama_indices):\n",
    "    \"\"\"searches for kdrama with matching name and returns top result\"\"\"\n",
    "    return kdrama_indices[kdrama_indices.index.str.contains(kdrama_name, regex=False, na=False)][0] \n",
    "\n",
    "def get_recommended_kdramas(target_kdrama_index, kdrama_similarities, kdramas_df, rec_num):\n",
    "    \"\"\"returns the top (rec_num) recommended kdramas based on keywords, genres, actors, director, director\n",
    "    and screenwriter (we recalculate their similarity score by using our own 'weights' :omg:)\"\"\"\n",
    "    if rec_num <= 1:\n",
    "        # return no kdramas\n",
    "        return False\n",
    "\n",
    "    # should set a max on how many recommended kdrama you can get (maybe like 25 or 50?)\n",
    "    similarity_scores = pd.DataFrame(kdrama_similarities[target_kdrama_index], columns=[\"score\"])\n",
    "    kdrama_indices = similarity_scores.sort_values(\"score\", ascending=False)[1:rec_num].index # gets top 10 (we can change this)\n",
    "    return kdramas_df['title'].iloc[kdrama_indices].values # converts to array\n",
    "\n",
    "def get_score(og_name, rec_name, indices, sim):\n",
    "    \"\"\"gets the similarity score of a kdrama based on ONE aspect (e.g. only keywords)\"\"\"\n",
    "    rec_index = search_kdrama(rec_name, indices)\n",
    "    scores = sim[search_kdrama(og_name, indices)]\n",
    "    return scores[rec_index]\n",
    "\n",
    "def vectorize_kdrama(col_name):\n",
    "    \"\"\"vectorizes the kdrama based on ONE aspect (e.g. only keywords)\"\"\"\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    return tfidf.fit_transform(df[col_name])\n",
    "\n",
    "def find_similarity(matrix):\n",
    "    \"\"\"finds the similarity between this matrix's kdrama and everything else\"\"\"\n",
    "    return cosine_similarity(matrix, matrix)\n",
    "\n",
    "def create_similarity_data(name):\n",
    "    \"\"\"creates a dictionary of arrays with the top 10 similar kdramas\"\"\"\n",
    "    similarity_data = {\n",
    "        \"titles\": [],\n",
    "        \"keywords\": [],\n",
    "        \"genres\": [],\n",
    "        \"actors\": [],\n",
    "        \"director\": [],\n",
    "        \"screenwriter\": [],\n",
    "    }\n",
    "\n",
    "    target_index = search_kdrama(name, get_indices())\n",
    "    top_ten = get_recommended_kdramas(target_index, og_cos_sim(), df, 10)\n",
    "\n",
    "    for kdrama in top_ten:\n",
    "        # adds this title to dictionary\n",
    "        similarity_data[\"titles\"].append(kdrama)\n",
    "        for label in label_weights.keys():\n",
    "            vec = vectorize_kdrama(label)\n",
    "            sim = find_similarity(vec)\n",
    "            label_score = get_score(name, kdrama, get_indices(), sim) * label_weights[label]\n",
    "            # print(label_score)\n",
    "            similarity_data[label].append(label_score)\n",
    "    \n",
    "    return similarity_data\n",
    "\n",
    "def get_top_rec_kdrama(name):\n",
    "    \"\"\"reorders the top recommended kdramas and converts to a dataframe\"\"\"\n",
    "    fill_na()\n",
    "    data = create_similarity_data(name)\n",
    "    new_df = pd.DataFrame(data)\n",
    "    new_df['score'] = new_df.sum(axis=1, numeric_only=True)\n",
    "    new_df = new_df.sort_values(\"score\", ascending=False)\n",
    "    print(new_df)\n",
    "\n",
    "get_top_rec_kdrama(\"Move to Heaven\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "607d36cc386bb86783cd5b11618343f80a7452933a7ad3095adf519582379640"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
